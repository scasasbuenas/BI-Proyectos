{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secci贸n 2. Entendimiento y Preparaci贸n de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta secci贸n tiene como prop贸sito exponer el entendimiento y la preparaci贸n de los textos para posteriormente utilizarlos en la implementaci贸n de los modelos de aprendizaje. Para la manipulaci贸n de los datos se usar谩n librerias como **pandas** y **numpy**. Para la visualizaci贸n se utilizar谩n **matplotlib**, **seaborn** y **WordCloud**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalaci贸n e importaci贸n de librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas numpy matplotlib seaborn scikit-learn nltk spacy wordcloud tqdm\n",
    "#%pip install spacy-langdetect\n",
    "#!python -m spacy download es_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mgs05\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Manipulaci贸n de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualizaci贸n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Procesamiento de texto\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Modelado y evaluaci贸n\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Progreso en bucles\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cargar modelo en espa帽ol de spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Descargar stopwords de NLTK en espa帽ol\n",
    "nltk.download('stopwords')\n",
    "stopwords_es = set(stopwords.words('spanish'))\n",
    "\n",
    "# Configuraci贸n de visualizaci贸n\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perfilamiento y entendimiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "data=pd.read_csv('fake_news_spanish.csv', sep=';', encoding = \"utf-8\")\n",
    "\n",
    "news_df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con S谩nchez: 'Europa necesit...</td>\n",
       "      <td>El diario brit谩nico public贸 este pasado jueves...</td>\n",
       "      <td>02/06/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIN ...</td>\n",
       "      <td>01/10/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castell贸 su fiesta...</td>\n",
       "      <td>25/04/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda D铆az, ERC y EH Bild...</td>\n",
       "      <td>En pol铆tica, igual que hay que negociar con lo...</td>\n",
       "      <td>03/01/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No ser铆a ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el l铆der de...</td>\n",
       "      <td>09/03/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Label                                             Titulo  \\\n",
       "0  ID      1  'The Guardian' va con S谩nchez: 'Europa necesit...   \n",
       "1  ID      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIN ...   \n",
       "2  ID      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3  ID      1  Iglesias alienta a Yolanda D铆az, ERC y EH Bild...   \n",
       "4  ID      0  Puigdemont: 'No ser铆a ninguna tragedia una rep...   \n",
       "\n",
       "                                         Descripcion       Fecha  \n",
       "0  El diario brit谩nico public贸 este pasado jueves...  02/06/2023  \n",
       "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIN ...  01/10/2023  \n",
       "2  El valencianismo convoca en Castell贸 su fiesta...  25/04/2022  \n",
       "3  En pol铆tica, igual que hay que negociar con lo...  03/01/2022  \n",
       "4  En una entrevista en El Punt Avui, el l铆der de...  09/03/2018  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57063 entries, 0 to 57062\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           57063 non-null  object\n",
      " 1   Label        57063 non-null  int64 \n",
      " 2   Titulo       57047 non-null  object\n",
      " 3   Descripcion  57063 non-null  object\n",
      " 4   Fecha        57063 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "news_df.info()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparaci贸n de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Limpieza de datos.\n",
    "\n",
    "Este c贸digo implementa un proceso de preprocesamiento de texto para limpiar datos textuales antes de realizar an谩lisis de texto o procesamiento de lenguaje natural.El preprocesamiento se aplica a dos columnas de un DataFrame (Titulo y Descripcion), generando nuevas columnas con los textos limpios (Titulo_Limpio y Descripcion_Limpia). Este paso es fundamental porque ayuda a reducir el ruido en los datos, mejora la precisi贸n de los modelos y facilita la extracci贸n de informaci贸n relevante eliminando t茅rminos irrelevantes o redundantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Comparaci贸n antes y despu茅s de la limpieza:\n",
      "                                              Titulo  \\\n",
      "0  'The Guardian' va con S谩nchez: 'Europa necesit...   \n",
      "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIN ...   \n",
      "2  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
      "3  Iglesias alienta a Yolanda D铆az, ERC y EH Bild...   \n",
      "4  Puigdemont: 'No ser铆a ninguna tragedia una rep...   \n",
      "\n",
      "                                       Titulo_Limpio  \n",
      "0  the guardian va sanchez europa necesita apuest...  \n",
      "1  revelan gobierno negocio liberacion mireles ca...  \n",
      "2  ahora nunca joan fuster estatuto valenciano cu...  \n",
      "3  iglesias alienta yolanda diaz erc eh bildu neg...  \n",
      "4  puigdemont seria ninguna tragedia repeticion e...  \n",
      "                                         Descripcion  \\\n",
      "0  El diario brit谩nico public贸 este pasado jueves...   \n",
      "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIN ...   \n",
      "2  El valencianismo convoca en Castell贸 su fiesta...   \n",
      "3  En pol铆tica, igual que hay que negociar con lo...   \n",
      "4  En una entrevista en El Punt Avui, el l铆der de...   \n",
      "\n",
      "                                  Descripcion_Limpia  \n",
      "0  diario britanico publico pasado jueves editori...  \n",
      "1  revelan gobierno negocio liberacion mireles ca...  \n",
      "2  valencianismo convoca castello fiesta grande c...  \n",
      "3  politica igual negociar empresarios negociar g...  \n",
      "4  entrevista punt avui lider jxcat desdramatizad...  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Funciones de preprocesamiento\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remueve caracteres no ASCII de una lista de palabras\"\"\"\n",
    "    return [unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore') for word in words if word]\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convierte todas las palabras a min煤sculas\"\"\"\n",
    "    return [word.lower() for word in words if word]\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Elimina signos de puntuaci贸n\"\"\"\n",
    "    return [re.sub(r'[^\\w\\s]', '', word) for word in words if re.sub(r'[^\\w\\s]', '', word) != '']\n",
    "\n",
    "def remove_numbers(words):\n",
    "    \"\"\"Elimina los n煤meros de la lista de palabras\"\"\"\n",
    "    return [word for word in words if not word.isdigit()]\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Elimina stopwords en espa帽ol\"\"\"\n",
    "    return [word for word in words if word not in stopwords_es]\n",
    "\n",
    "def preprocessing(text):\n",
    "    \"\"\"Aplica todas las funciones de limpieza de texto a un string\"\"\"\n",
    "    words = word_tokenize(text, language=\"spanish\")  # Tokenizar con NLTK\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return \" \".join(words)  # Retorna el texto limpio como un string\n",
    "\n",
    "# Aplicar limpieza en el DataFrame\n",
    "news_df['Titulo_Limpio'] = news_df['Titulo'].astype(str).apply(preprocessing)\n",
    "news_df['Descripcion_Limpia'] = news_df['Descripcion'].astype(str).apply(preprocessing)\n",
    "\n",
    "# Comparaci贸n antes y despu茅s\n",
    "print(\" Comparaci贸n antes y despu茅s de la limpieza:\")\n",
    "print(news_df[['Titulo', 'Titulo_Limpio']].head())\n",
    "print(news_df[['Descripcion', 'Descripcion_Limpia']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Tokenizaci贸n\n",
    "\n",
    "Este c贸digo realiza la tokenizaci贸n de texto. Esta tokenizaci贸n se aplica a las columnas ya limpias del DataFrame (Titulo_Limpio y Descripcion_Limpia), generando nuevas columnas Titulo_Tokens y Descripcion_Tokens, donde cada texto se representa como una lista de palabras. Este paso es crucial porque permite a los modelos de an谩lisis de texto procesar los datos de manera estructurada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaci贸n despu茅s de la tokenizaci贸n:\n",
      "                                       Titulo_Limpio  \\\n",
      "0  the guardian va sanchez europa necesita apuest...   \n",
      "1  revelan gobierno negocio liberacion mireles ca...   \n",
      "2  ahora nunca joan fuster estatuto valenciano cu...   \n",
      "3  iglesias alienta yolanda diaz erc eh bildu neg...   \n",
      "4  puigdemont seria ninguna tragedia repeticion e...   \n",
      "\n",
      "                                       Titulo_Tokens  \n",
      "0  [the, guardian, va, sanchez, europa, necesita,...  \n",
      "1  [revelan, gobierno, negocio, liberacion, mirel...  \n",
      "2  [ahora, nunca, joan, fuster, estatuto, valenci...  \n",
      "3  [iglesias, alienta, yolanda, diaz, erc, eh, bi...  \n",
      "4  [puigdemont, seria, ninguna, tragedia, repetic...  \n",
      "                                  Descripcion_Limpia  \\\n",
      "0  diario britanico publico pasado jueves editori...   \n",
      "1  revelan gobierno negocio liberacion mireles ca...   \n",
      "2  valencianismo convoca castello fiesta grande c...   \n",
      "3  politica igual negociar empresarios negociar g...   \n",
      "4  entrevista punt avui lider jxcat desdramatizad...   \n",
      "\n",
      "                                  Descripcion_Tokens  \n",
      "0  [diario, britanico, publico, pasado, jueves, e...  \n",
      "1  [revelan, gobierno, negocio, liberacion, mirel...  \n",
      "2  [valencianismo, convoca, castello, fiesta, gra...  \n",
      "3  [politica, igual, negociar, empresarios, negoc...  \n",
      "4  [entrevista, punt, avui, lider, jxcat, desdram...  \n"
     ]
    }
   ],
   "source": [
    "def tokenize_nltk(text):\n",
    "    return word_tokenize(text, language=\"spanish\")\n",
    "\n",
    "# Aplicar tokenizaci贸n en las columnas ya limpias\n",
    "news_df['Titulo_Tokens'] = news_df['Titulo_Limpio'].astype(str).apply(tokenize_nltk)\n",
    "news_df['Descripcion_Tokens'] = news_df['Descripcion_Limpia'].astype(str).apply(tokenize_nltk)\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(\"Comparaci贸n despu茅s de la tokenizaci贸n:\")\n",
    "print(news_df[['Titulo_Limpio', 'Titulo_Tokens']].head())\n",
    "print(news_df[['Descripcion_Limpia', 'Descripcion_Tokens']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Normalizaci贸n\n",
    "\n",
    "Este c贸digo realiza la normalizaci贸n del texto aplicando t茅cnicas de stemming y lemmatizaci贸n. La normalizaci贸n se aplica a las columnas del DataFrame (Titulo_Tokens y Descripcion_Tokens), generando nuevas columnas Titulo_Normalizado y Descripcion_Normalizada, donde cada palabra es reducida a su ra铆z. Este paso es fundamental porque mejora la consistencia del texto y facilita el procesamiento de datos en modelos de an谩lisis de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mgs05\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mgs05\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaci贸n despu茅s de la normalizaci贸n:\n",
      "                                       Titulo_Tokens  \\\n",
      "0  [the, guardian, va, sanchez, europa, necesita,...   \n",
      "1  [revelan, gobierno, negocio, liberacion, mirel...   \n",
      "2  [ahora, nunca, joan, fuster, estatuto, valenci...   \n",
      "3  [iglesias, alienta, yolanda, diaz, erc, eh, bi...   \n",
      "4  [puigdemont, seria, ninguna, tragedia, repetic...   \n",
      "\n",
      "                                  Titulo_Normalizado  \n",
      "0  [guardian, sanchez, va, guardi, apuest, europ,...  \n",
      "1  [cambio, negoci, javier, duart, gobiern, javi,...  \n",
      "2  [fuster, anos, valenciano, cumple, nunc, ahor,...  \n",
      "3  [negoci, iglesias, investidura, alient, bloqu,...  \n",
      "4  [eleccion, elecciones, ninguna, ningun, seri, ...  \n",
      "                                  Descripcion_Tokens  \\\n",
      "0  [diario, britanico, publico, pasado, jueves, e...   \n",
      "1  [revelan, gobierno, negocio, liberacion, mirel...   \n",
      "2  [valencianismo, convoca, castello, fiesta, gra...   \n",
      "3  [politica, igual, negociar, empresarios, negoc...   \n",
      "4  [entrevista, punt, avui, lider, jxcat, desdram...   \n",
      "\n",
      "                             Descripcion_Normalizada  \n",
      "0  [eleccion, president, apoya, riesg, presidente...  \n",
      "1  [preferencial, par, duart, turbios, liberarlo,...  \n",
      "2  [fiesta, batalla, castell, plaza, castello, co...  \n",
      "3  [parlamentari, negoci, parlamentarios, politic...  \n",
      "4  [acabe, eleccion, escenari, cup, trab, teo, ga...  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Descargar recursos necesarios para lematizaci贸n\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Crear los objetos para stemming y lematizaci贸n\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Aplica stemming para eliminar prefijos y sufijos en las palabras\"\"\"\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Aplica lematizaci贸n para obtener la ra铆z de los verbos\"\"\"\n",
    "    return [lemmatizer.lemmatize(word, wordnet.VERB) for word in words]\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    \"\"\"Combina stemming y lematizaci贸n para normalizar los datos\"\"\"\n",
    "    stemmed = stem_words(words)\n",
    "    lemmatized = lemmatize_verbs(words)\n",
    "    return list(set(stemmed + lemmatized))  # Se usa set() para evitar duplicados\n",
    "\n",
    "# Aplicar normalizaci贸n a las columnas tokenizadas\n",
    "news_df['Titulo_Normalizado'] = news_df['Titulo_Tokens'].apply(stem_and_lemmatize)\n",
    "news_df['Descripcion_Normalizada'] = news_df['Descripcion_Tokens'].apply(stem_and_lemmatize)\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(\"Comparaci贸n despu茅s de la normalizaci贸n:\")\n",
    "print(news_df[['Titulo_Tokens', 'Titulo_Normalizado']].head())\n",
    "print(news_df[['Descripcion_Tokens', 'Descripcion_Normalizada']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
