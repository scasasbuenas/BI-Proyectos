{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 2. Entendimiento y Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta sección tiene como propósito exponer el entendimiento y la preparación de los textos para posteriormente utilizarlos en la implementación de los modelos de aprendizaje. Para la manipulación de los datos se usarán librerias como **pandas** y **numpy**. Para la visualización se utilizarán **matplotlib**, **seaborn** y **WordCloud**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalación e importación de librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas numpy matplotlib seaborn scikit-learn nltk spacy wordcloud tqdm\n",
    "#%pip install spacy-langdetect\n",
    "#!python -m spacy download es_core_news_sm\n",
    "#%pip install tensorflow\n",
    "#%pip install keras\n",
    "#!pip install wordcloud\n",
    "#!pip install spacy-langdetect\n",
    "#!python -m spacy download es_core_news_sm\n",
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "#!pip install spacy\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mgs05\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Procesamiento de texto\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Modelado y evaluación\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, precision_score, f1_score, ConfusionMatrixDisplay,precision_recall_curve\n",
    "\n",
    "\n",
    "# Para búsqueda de hiperparámetros\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "#from ydata_profiling import ProfileReport\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Cargar modelo en español de spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Descargar stopwords de NLTK en español\n",
    "nltk.download('stopwords')\n",
    "stopwords_es = set(stopwords.words('spanish'))\n",
    "\n",
    "# Configuración de visualización\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perfilamiento y entendimiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Limpieza de datos.\n",
    "\n",
    "Este código implementa un proceso de preprocesamiento de texto para limpiar datos textuales antes de realizar análisis de texto o procesamiento de lenguaje natural.El preprocesamiento se aplica a dos columnas de un DataFrame (Titulo y Descripcion), generando nuevas columnas con los textos limpios (Titulo_Limpio y Descripcion_Limpia). Este paso es fundamental porque ayuda a reducir el ruido en los datos, mejora la precisión de los modelos y facilita la extracción de información relevante eliminando términos irrelevantes o redundantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "data=pd.read_csv('./deception/data/fake_news_spanish.csv', sep=';', encoding = \"utf-8\")\n",
    "news_df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Titulo_Limpio</th>\n",
       "      <th>Descripcion_Limpia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>the guardian va sanchez europa necesita apuest...</td>\n",
       "      <td>diario britanico publico pasado jueves editori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>revelan gobierno negocio liberacion mireles ca...</td>\n",
       "      <td>revelan gobierno negocio liberacion mireles ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>ahora nunca joan fuster estatuto valenciano cu...</td>\n",
       "      <td>valencianismo convoca castello fiesta grande c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>iglesias alienta yolanda diaz erc eh bildu neg...</td>\n",
       "      <td>politica igual negociar empresarios negociar g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>puigdemont seria ninguna tragedia repeticion e...</td>\n",
       "      <td>entrevista punt avui lider jxcat desdramatizad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                             Titulo  \\\n",
       "0      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "\n",
       "                                         Descripcion  \\\n",
       "0  El diario británico publicó este pasado jueves...   \n",
       "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2  El valencianismo convoca en Castelló su fiesta...   \n",
       "3  En política, igual que hay que negociar con lo...   \n",
       "4  En una entrevista en El Punt Avui, el líder de...   \n",
       "\n",
       "                                       Titulo_Limpio  \\\n",
       "0  the guardian va sanchez europa necesita apuest...   \n",
       "1  revelan gobierno negocio liberacion mireles ca...   \n",
       "2  ahora nunca joan fuster estatuto valenciano cu...   \n",
       "3  iglesias alienta yolanda diaz erc eh bildu neg...   \n",
       "4  puigdemont seria ninguna tragedia repeticion e...   \n",
       "\n",
       "                                  Descripcion_Limpia  \n",
       "0  diario britanico publico pasado jueves editori...  \n",
       "1  revelan gobierno negocio liberacion mireles ca...  \n",
       "2  valencianismo convoca castello fiesta grande c...  \n",
       "3  politica igual negociar empresarios negociar g...  \n",
       "4  entrevista punt avui lider jxcat desdramatizad...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "news_df = news_df[[\"Label\", \"Titulo\", \"Descripcion\"]]\n",
    "\n",
    "# Funciones de preprocesamiento\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remueve caracteres no ASCII de una lista de palabras\"\"\"\n",
    "    return [unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore') for word in words if word]\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convierte todas las palabras a minúsculas\"\"\"\n",
    "    return [word.lower() for word in words if word]\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Elimina signos de puntuación\"\"\"\n",
    "    return [re.sub(r'[^\\w\\s]', '', word) for word in words if re.sub(r'[^\\w\\s]', '', word) != '']\n",
    "\n",
    "def remove_numbers(words):\n",
    "    \"\"\"Elimina los números de la lista de palabras\"\"\"\n",
    "    return [word for word in words if not word.isdigit()]\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Elimina stopwords en español\"\"\"\n",
    "    return [word for word in words if word not in stopwords_es]\n",
    "\n",
    "def preprocessing(text):\n",
    "    \"\"\"Aplica todas las funciones de limpieza de texto a un string\"\"\"\n",
    "    words = word_tokenize(text, language=\"spanish\")  # Tokenizar con NLTK\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return \" \".join(words)  # Retorna el texto limpio como un string\n",
    "\n",
    "# Aplicar limpieza en el DataFrame\n",
    "news_df['Titulo_Limpio'] = news_df['Titulo'].astype(str).apply(preprocessing)\n",
    "news_df['Descripcion_Limpia'] = news_df['Descripcion'].astype(str).apply(preprocessing)\n",
    "\n",
    "# Comparación antes y después\n",
    "news_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Tokenización\n",
    "\n",
    "Este código realiza la tokenización de texto. Esta tokenización se aplica a las columnas ya limpias del DataFrame (Titulo_Limpio y Descripcion_Limpia), generando nuevas columnas Titulo_Tokens y Descripcion_Tokens, donde cada texto se representa como una lista de palabras. Este paso es crucial porque permite a los modelos de análisis de texto procesar los datos de manera estructurada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación después de la tokenización:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Titulo_Limpio</th>\n",
       "      <th>Descripcion_Limpia</th>\n",
       "      <th>Titulo_Tokens</th>\n",
       "      <th>Descripcion_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>the guardian va sanchez europa necesita apuest...</td>\n",
       "      <td>diario britanico publico pasado jueves editori...</td>\n",
       "      <td>[the, guardian, va, sanchez, europa, necesita,...</td>\n",
       "      <td>[diario, britanico, publico, pasado, jueves, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>revelan gobierno negocio liberacion mireles ca...</td>\n",
       "      <td>revelan gobierno negocio liberacion mireles ca...</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>ahora nunca joan fuster estatuto valenciano cu...</td>\n",
       "      <td>valencianismo convoca castello fiesta grande c...</td>\n",
       "      <td>[ahora, nunca, joan, fuster, estatuto, valenci...</td>\n",
       "      <td>[valencianismo, convoca, castello, fiesta, gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>iglesias alienta yolanda diaz erc eh bildu neg...</td>\n",
       "      <td>politica igual negociar empresarios negociar g...</td>\n",
       "      <td>[iglesias, alienta, yolanda, diaz, erc, eh, bi...</td>\n",
       "      <td>[politica, igual, negociar, empresarios, negoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>puigdemont seria ninguna tragedia repeticion e...</td>\n",
       "      <td>entrevista punt avui lider jxcat desdramatizad...</td>\n",
       "      <td>[puigdemont, seria, ninguna, tragedia, repetic...</td>\n",
       "      <td>[entrevista, punt, avui, lider, jxcat, desdram...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                             Titulo  \\\n",
       "0      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "\n",
       "                                         Descripcion  \\\n",
       "0  El diario británico publicó este pasado jueves...   \n",
       "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2  El valencianismo convoca en Castelló su fiesta...   \n",
       "3  En política, igual que hay que negociar con lo...   \n",
       "4  En una entrevista en El Punt Avui, el líder de...   \n",
       "\n",
       "                                       Titulo_Limpio  \\\n",
       "0  the guardian va sanchez europa necesita apuest...   \n",
       "1  revelan gobierno negocio liberacion mireles ca...   \n",
       "2  ahora nunca joan fuster estatuto valenciano cu...   \n",
       "3  iglesias alienta yolanda diaz erc eh bildu neg...   \n",
       "4  puigdemont seria ninguna tragedia repeticion e...   \n",
       "\n",
       "                                  Descripcion_Limpia  \\\n",
       "0  diario britanico publico pasado jueves editori...   \n",
       "1  revelan gobierno negocio liberacion mireles ca...   \n",
       "2  valencianismo convoca castello fiesta grande c...   \n",
       "3  politica igual negociar empresarios negociar g...   \n",
       "4  entrevista punt avui lider jxcat desdramatizad...   \n",
       "\n",
       "                                       Titulo_Tokens  \\\n",
       "0  [the, guardian, va, sanchez, europa, necesita,...   \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...   \n",
       "2  [ahora, nunca, joan, fuster, estatuto, valenci...   \n",
       "3  [iglesias, alienta, yolanda, diaz, erc, eh, bi...   \n",
       "4  [puigdemont, seria, ninguna, tragedia, repetic...   \n",
       "\n",
       "                                  Descripcion_Tokens  \n",
       "0  [diario, britanico, publico, pasado, jueves, e...  \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...  \n",
       "2  [valencianismo, convoca, castello, fiesta, gra...  \n",
       "3  [politica, igual, negociar, empresarios, negoc...  \n",
       "4  [entrevista, punt, avui, lider, jxcat, desdram...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_nltk(text):\n",
    "    return word_tokenize(text, language=\"spanish\")\n",
    "\n",
    "# Aplicar tokenización en las columnas ya limpias\n",
    "news_df['Titulo_Tokens'] = news_df['Titulo_Limpio'].astype(str).apply(tokenize_nltk)\n",
    "news_df['Descripcion_Tokens'] = news_df['Descripcion_Limpia'].astype(str).apply(tokenize_nltk)\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(\"Comparación después de la tokenización:\")\n",
    "news_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Lematización\n",
    "\n",
    "Este código realiza la normalización del texto aplicando técnicas de stemming y lemmatización. La normalización se aplica a las columnas del DataFrame (Titulo_Tokens y Descripcion_Tokens), generando nuevas columnas Titulo_Normalizado y Descripcion_Normalizada, donde cada palabra es reducida a su raíz. Este paso es fundamental porque mejora la consistencia del texto y facilita el procesamiento de datos en modelos de análisis de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación después de la normalización:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Titulo_Limpio</th>\n",
       "      <th>Descripcion_Limpia</th>\n",
       "      <th>Titulo_Tokens</th>\n",
       "      <th>Descripcion_Tokens</th>\n",
       "      <th>Titulo_Normalizado</th>\n",
       "      <th>Descripcion_Normalizada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>the guardian va sanchez europa necesita apuest...</td>\n",
       "      <td>diario britanico publico pasado jueves editori...</td>\n",
       "      <td>[the, guardian, va, sanchez, europa, necesita,...</td>\n",
       "      <td>[diario, britanico, publico, pasado, jueves, e...</td>\n",
       "      <td>[necesit, europ, frut, va, apuesta, europa, sa...</td>\n",
       "      <td>[adelanto, alerte, valiente, britanico, apoya,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>revelan gobierno negocio liberacion mireles ca...</td>\n",
       "      <td>revelan gobierno negocio liberacion mireles ca...</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "      <td>[gobiern, revelan, cambi, javi, negoci, liber,...</td>\n",
       "      <td>[armamento, trato, lanz, injusticias, salir, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>ahora nunca joan fuster estatuto valenciano cu...</td>\n",
       "      <td>valencianismo convoca castello fiesta grande c...</td>\n",
       "      <td>[ahora, nunca, joan, fuster, estatuto, valenci...</td>\n",
       "      <td>[valencianismo, convoca, castello, fiesta, gra...</td>\n",
       "      <td>[fuster, joan, nunca, cumple, estatuto, ahor, ...</td>\n",
       "      <td>[valencianismo, fiesta, estatut, plana, plan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>iglesias alienta yolanda diaz erc eh bildu neg...</td>\n",
       "      <td>politica igual negociar empresarios negociar g...</td>\n",
       "      <td>[iglesias, alienta, yolanda, diaz, erc, eh, bi...</td>\n",
       "      <td>[politica, igual, negociar, empresarios, negoc...</td>\n",
       "      <td>[bildu, yolanda, erc, bloque, negoci, investid...</td>\n",
       "      <td>[igual, empresarios, grup, iglesi, reflexionad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>puigdemont seria ninguna tragedia repeticion e...</td>\n",
       "      <td>entrevista punt avui lider jxcat desdramatizad...</td>\n",
       "      <td>[puigdemont, seria, ninguna, tragedia, repetic...</td>\n",
       "      <td>[entrevista, punt, avui, lider, jxcat, desdram...</td>\n",
       "      <td>[repeticion, tragedia, elecciones, seria, ning...</td>\n",
       "      <td>[invest, elecciones, jxcat, investidura, desdr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                             Titulo  \\\n",
       "0      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "\n",
       "                                         Descripcion  \\\n",
       "0  El diario británico publicó este pasado jueves...   \n",
       "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2  El valencianismo convoca en Castelló su fiesta...   \n",
       "3  En política, igual que hay que negociar con lo...   \n",
       "4  En una entrevista en El Punt Avui, el líder de...   \n",
       "\n",
       "                                       Titulo_Limpio  \\\n",
       "0  the guardian va sanchez europa necesita apuest...   \n",
       "1  revelan gobierno negocio liberacion mireles ca...   \n",
       "2  ahora nunca joan fuster estatuto valenciano cu...   \n",
       "3  iglesias alienta yolanda diaz erc eh bildu neg...   \n",
       "4  puigdemont seria ninguna tragedia repeticion e...   \n",
       "\n",
       "                                  Descripcion_Limpia  \\\n",
       "0  diario britanico publico pasado jueves editori...   \n",
       "1  revelan gobierno negocio liberacion mireles ca...   \n",
       "2  valencianismo convoca castello fiesta grande c...   \n",
       "3  politica igual negociar empresarios negociar g...   \n",
       "4  entrevista punt avui lider jxcat desdramatizad...   \n",
       "\n",
       "                                       Titulo_Tokens  \\\n",
       "0  [the, guardian, va, sanchez, europa, necesita,...   \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...   \n",
       "2  [ahora, nunca, joan, fuster, estatuto, valenci...   \n",
       "3  [iglesias, alienta, yolanda, diaz, erc, eh, bi...   \n",
       "4  [puigdemont, seria, ninguna, tragedia, repetic...   \n",
       "\n",
       "                                  Descripcion_Tokens  \\\n",
       "0  [diario, britanico, publico, pasado, jueves, e...   \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...   \n",
       "2  [valencianismo, convoca, castello, fiesta, gra...   \n",
       "3  [politica, igual, negociar, empresarios, negoc...   \n",
       "4  [entrevista, punt, avui, lider, jxcat, desdram...   \n",
       "\n",
       "                                  Titulo_Normalizado  \\\n",
       "0  [necesit, europ, frut, va, apuesta, europa, sa...   \n",
       "1  [gobiern, revelan, cambi, javi, negoci, liber,...   \n",
       "2  [fuster, joan, nunca, cumple, estatuto, ahor, ...   \n",
       "3  [bildu, yolanda, erc, bloque, negoci, investid...   \n",
       "4  [repeticion, tragedia, elecciones, seria, ning...   \n",
       "\n",
       "                             Descripcion_Normalizada  \n",
       "0  [adelanto, alerte, valiente, britanico, apoya,...  \n",
       "1  [armamento, trato, lanz, injusticias, salir, c...  \n",
       "2  [valencianismo, fiesta, estatut, plana, plan, ...  \n",
       "3  [igual, empresarios, grup, iglesi, reflexionad...  \n",
       "4  [invest, elecciones, jxcat, investidura, desdr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Descargar recursos necesarios para lematización\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "# Crear los objetos para stemming y lematización\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Aplica stemming para eliminar prefijos y sufijos en las palabras\"\"\"\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Aplica lematización para obtener la raíz de los verbos\"\"\"\n",
    "    return [lemmatizer.lemmatize(word, wordnet.VERB) for word in words]\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    \"\"\"Combina stemming y lematización para normalizar los datos\"\"\"\n",
    "    stemmed = stem_words(words)\n",
    "    lemmatized = lemmatize_verbs(words)\n",
    "    return list(set(stemmed + lemmatized))  # Se usa set() para evitar duplicados\n",
    "\n",
    "# Aplicar normalización a las columnas tokenizadas\n",
    "news_df['Titulo_Normalizado'] = news_df['Titulo_Tokens'].apply(stem_and_lemmatize)\n",
    "news_df['Descripcion_Normalizada'] = news_df['Descripcion_Tokens'].apply(stem_and_lemmatize)\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(\"Comparación después de la normalización:\")\n",
    "news_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mostrarán solamente: Los tokens del título, los tokens de la descripción, el titulo normalizado y la descripción normalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo_Tokens</th>\n",
       "      <th>Descripcion_Tokens</th>\n",
       "      <th>Titulo_Normalizado</th>\n",
       "      <th>Descripcion_Normalizada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[the, guardian, va, sanchez, europa, necesita,...</td>\n",
       "      <td>[diario, britanico, publico, pasado, jueves, e...</td>\n",
       "      <td>[necesit, europ, frut, va, apuesta, europa, sa...</td>\n",
       "      <td>[adelanto, alerte, valiente, britanico, apoya,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "      <td>[gobiern, revelan, cambi, javi, negoci, liber,...</td>\n",
       "      <td>[armamento, trato, lanz, injusticias, salir, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[ahora, nunca, joan, fuster, estatuto, valenci...</td>\n",
       "      <td>[valencianismo, convoca, castello, fiesta, gra...</td>\n",
       "      <td>[fuster, joan, nunca, cumple, estatuto, ahor, ...</td>\n",
       "      <td>[valencianismo, fiesta, estatut, plana, plan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[iglesias, alienta, yolanda, diaz, erc, eh, bi...</td>\n",
       "      <td>[politica, igual, negociar, empresarios, negoc...</td>\n",
       "      <td>[bildu, yolanda, erc, bloque, negoci, investid...</td>\n",
       "      <td>[igual, empresarios, grup, iglesi, reflexionad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[puigdemont, seria, ninguna, tragedia, repetic...</td>\n",
       "      <td>[entrevista, punt, avui, lider, jxcat, desdram...</td>\n",
       "      <td>[repeticion, tragedia, elecciones, seria, ning...</td>\n",
       "      <td>[invest, elecciones, jxcat, investidura, desdr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                      Titulo_Tokens  \\\n",
       "0      1  [the, guardian, va, sanchez, europa, necesita,...   \n",
       "1      0  [revelan, gobierno, negocio, liberacion, mirel...   \n",
       "2      1  [ahora, nunca, joan, fuster, estatuto, valenci...   \n",
       "3      1  [iglesias, alienta, yolanda, diaz, erc, eh, bi...   \n",
       "4      0  [puigdemont, seria, ninguna, tragedia, repetic...   \n",
       "\n",
       "                                  Descripcion_Tokens  \\\n",
       "0  [diario, britanico, publico, pasado, jueves, e...   \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...   \n",
       "2  [valencianismo, convoca, castello, fiesta, gra...   \n",
       "3  [politica, igual, negociar, empresarios, negoc...   \n",
       "4  [entrevista, punt, avui, lider, jxcat, desdram...   \n",
       "\n",
       "                                  Titulo_Normalizado  \\\n",
       "0  [necesit, europ, frut, va, apuesta, europa, sa...   \n",
       "1  [gobiern, revelan, cambi, javi, negoci, liber,...   \n",
       "2  [fuster, joan, nunca, cumple, estatuto, ahor, ...   \n",
       "3  [bildu, yolanda, erc, bloque, negoci, investid...   \n",
       "4  [repeticion, tragedia, elecciones, seria, ning...   \n",
       "\n",
       "                             Descripcion_Normalizada  \n",
       "0  [adelanto, alerte, valiente, britanico, apoya,...  \n",
       "1  [armamento, trato, lanz, injusticias, salir, c...  \n",
       "2  [valencianismo, fiesta, estatut, plana, plan, ...  \n",
       "3  [igual, empresarios, grup, iglesi, reflexionad...  \n",
       "4  [invest, elecciones, jxcat, investidura, desdr...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = news_df[['Label', 'Titulo_Tokens', 'Descripcion_Tokens', 'Titulo_Normalizado', 'Descripcion_Normalizada']]\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora unificaremos los titulos y las descripciones normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo_Tokens</th>\n",
       "      <th>Descripcion_Tokens</th>\n",
       "      <th>Titulo_Normalizado</th>\n",
       "      <th>Descripcion_Normalizada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[the, guardian, va, sanchez, europa, necesita,...</td>\n",
       "      <td>[diario, britanico, publico, pasado, jueves, e...</td>\n",
       "      <td>necesit europ frut va apuesta europa sanchez g...</td>\n",
       "      <td>adelanto alerte valiente britanico apoya elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "      <td>gobiern revelan cambi javi negoci liber duart ...</td>\n",
       "      <td>armamento trato lanz injusticias salir comienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[ahora, nunca, joan, fuster, estatuto, valenci...</td>\n",
       "      <td>[valencianismo, convoca, castello, fiesta, gra...</td>\n",
       "      <td>fuster joan nunca cumple estatuto ahor anos es...</td>\n",
       "      <td>valencianismo fiesta estatut plana plan plen p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[iglesias, alienta, yolanda, diaz, erc, eh, bi...</td>\n",
       "      <td>[politica, igual, negociar, empresarios, negoc...</td>\n",
       "      <td>bildu yolanda erc bloque negoci investidura re...</td>\n",
       "      <td>igual empresarios grup iglesi reflexionado par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[puigdemont, seria, ninguna, tragedia, repetic...</td>\n",
       "      <td>[entrevista, punt, avui, lider, jxcat, desdram...</td>\n",
       "      <td>repeticion tragedia elecciones seria ningun ni...</td>\n",
       "      <td>invest elecciones jxcat investidura desdramati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                      Titulo_Tokens  \\\n",
       "0      1  [the, guardian, va, sanchez, europa, necesita,...   \n",
       "1      0  [revelan, gobierno, negocio, liberacion, mirel...   \n",
       "2      1  [ahora, nunca, joan, fuster, estatuto, valenci...   \n",
       "3      1  [iglesias, alienta, yolanda, diaz, erc, eh, bi...   \n",
       "4      0  [puigdemont, seria, ninguna, tragedia, repetic...   \n",
       "\n",
       "                                  Descripcion_Tokens  \\\n",
       "0  [diario, britanico, publico, pasado, jueves, e...   \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...   \n",
       "2  [valencianismo, convoca, castello, fiesta, gra...   \n",
       "3  [politica, igual, negociar, empresarios, negoc...   \n",
       "4  [entrevista, punt, avui, lider, jxcat, desdram...   \n",
       "\n",
       "                                  Titulo_Normalizado  \\\n",
       "0  necesit europ frut va apuesta europa sanchez g...   \n",
       "1  gobiern revelan cambi javi negoci liber duart ...   \n",
       "2  fuster joan nunca cumple estatuto ahor anos es...   \n",
       "3  bildu yolanda erc bloque negoci investidura re...   \n",
       "4  repeticion tragedia elecciones seria ningun ni...   \n",
       "\n",
       "                             Descripcion_Normalizada  \n",
       "0  adelanto alerte valiente britanico apoya elect...  \n",
       "1  armamento trato lanz injusticias salir comienc...  \n",
       "2  valencianismo fiesta estatut plana plan plen p...  \n",
       "3  igual empresarios grup iglesi reflexionado par...  \n",
       "4  invest elecciones jxcat investidura desdramati...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacer copia del dataframe procesado\n",
    "processed_news_df = processed_df.copy()\n",
    "\n",
    "# Convertir las listas de palabras en texto separado por espacios en las columnas Titulo_Normalizado y Descripcion_Normalizada\n",
    "processed_news_df['Titulo_Normalizado'] = processed_news_df['Titulo_Normalizado'].apply(lambda tokens: \" \".join(tokens))\n",
    "processed_news_df['Descripcion_Normalizada'] = processed_news_df['Descripcion_Normalizada'].apply(lambda tokens: \" \".join(tokens))\n",
    "\n",
    "# Mostrar algunos ejemplos para verificar el cambio\n",
    "processed_news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construcción de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los datos que tenemos son datos de texto, debemos de alguna maner convertir estos datos en valores interpretables por el modelo para generar información relevante que podamos interpretar. En este caso, usaremos a nuestro favor la **vectorización de texto** a partir del método TF-IDF ya que es una opción balanceada entre simplicidad y efectividad. La idea es convertir los textos de 'Titulo_Normalizado' y 'Descripcion_Normalizada' en vectores numéricos usando TF-IDF y luego usarlos para entrenar un modelo de clasificación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Transformación TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de la matriz de características X: (57063, 91339)\n",
      "Dimensión de la variable objetivo y: (57063,)\n"
     ]
    }
   ],
   "source": [
    "# Definimos el vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer()  # Limitamos el número de características para evitar alta dimensionalidad\n",
    "\n",
    "# Aplicamos la transformación TF-IDF a las columnas normalizadas\n",
    "titulo_tfidf = vectorizer.fit_transform(processed_news_df['Titulo_Normalizado'])\n",
    "descripcion_tfidf = vectorizer.fit_transform(processed_news_df['Descripcion_Normalizada'])\n",
    "\n",
    "# Concatenamos ambas representaciones para tener una única matriz de características\n",
    "X = hstack([titulo_tfidf, descripcion_tfidf])\n",
    "# Definimos la variable objetivo\n",
    "y = processed_news_df['Label']\n",
    "\n",
    "# Mostramos la forma de la matriz final\n",
    "print(\"Dimensión de la matriz de características X:\", X.shape)\n",
    "print(\"Dimensión de la variable objetivo y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUXILIAR\n",
    "\n",
    "# Aplicamos la transformación TF-IDF a las columnas normalizadas\n",
    "titulo_tfidf = vectorizer.fit_transform(processed_news_df['Titulo_Normalizado'])\n",
    "descripcion_tfidf = vectorizer.fit_transform(processed_news_df['Descripcion_Normalizada'])\n",
    "\n",
    "# Concatenamos ambas representaciones para tener una única matriz de características\n",
    "X = hstack([titulo_tfidf, descripcion_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Entrenamiento del primer modelo de clasificación - Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos un modelo clásico de Regresión Logística, ya que es simple, eficiente y suele funcionar bien en tareas de clasificación de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Inicializamos y entrenamos el modelo de Regresión Logística\n",
    "modelo = LogisticRegression(max_iter=1000)  # Aumentamos las iteraciones para asegurar convergencia\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones sobre el conjunto de prueba\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Evaluamos el modelo con una matriz de confusión y métricas de desempeño\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Resultados de la Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.1 Reporte de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.89\n",
      "Recall: 0.9632086851628469\n",
      "Precisión: 0.8637101135749053\n",
      "Puntuación F1: 0.9107499287140006\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86      4781\n",
      "           1       0.86      0.96      0.91      6632\n",
      "\n",
      "    accuracy                           0.89     11413\n",
      "   macro avg       0.90      0.88      0.88     11413\n",
      "weighted avg       0.90      0.89      0.89     11413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los resultados\n",
    "print('Exactitud: %.2f' % accuracy_score(y_test, y_pred))\n",
    "print(\"Recall: {}\".format(recall_score(y_test,y_pred)))\n",
    "print(\"Precisión: {}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Puntuación F1: {}\".format(f1_score(y_test,y_pred)))\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.2 Matríz de Confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.4 Modificación del Umbral de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la curva Presición-Recall en función del Umbral de Clasificación**\n",
    "\n",
    "El punto de equilibrio lo encontramos entre 0.6 y 0.7 podemos empezar a experimentar con estos valores y evaluar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de Clasificación (Umbral 0.6):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.87      4781\n",
      "           1       0.89      0.93      0.91      6632\n",
      "\n",
      "    accuracy                           0.89     11413\n",
      "   macro avg       0.89      0.88      0.89     11413\n",
      "weighted avg       0.89      0.89      0.89     11413\n",
      "\n",
      "\n",
      "Exactitud del modelo (Umbral 0.6): 0.8911\n"
     ]
    }
   ],
   "source": [
    "# Definimos el nuevo umbral\n",
    "nuevo_umbral = 0.6\n",
    "y_prob = modelo.predict_proba(X_test)[:, 1] \n",
    "# Aplicamos el nuevo umbral a las predicciones\n",
    "y_pred_ajustado = (y_prob >= nuevo_umbral).astype(int)\n",
    "\n",
    "# Calculamos las nuevas métricas\n",
    "from sklearn.metrics import  accuracy_score, classification_report\n",
    "\n",
    "accuracy_ajustada = accuracy_score(y_test, y_pred_ajustado)\n",
    "classification_rep_ajustado = classification_report(y_test, y_pred_ajustado)\n",
    "\n",
    "print(\"\\nReporte de Clasificación (Umbral 0.6):\")\n",
    "print(classification_rep_ajustado)\n",
    "print(f\"\\nExactitud del modelo (Umbral 0.6): {accuracy_ajustada:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
